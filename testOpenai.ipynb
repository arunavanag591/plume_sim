{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "flexible-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import requests\n",
    "import json\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "australian-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_first_cell(file_path):\n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    sheet = workbook.active\n",
    "    first_cell = sheet.cell(row=1, column=1)\n",
    "    return first_cell.value\n",
    "\n",
    "file_path = '../openaikey.xlsx'  # Replace with the path to your Excel file\n",
    "first_cell_value = read_first_cell(file_path)\n",
    "\n",
    "openai.api_key=first_cell_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "false-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '~/Documents/MyFiles/DataAnalysis/data/Sprints/HighRes/'\n",
    "df = pd.read_hdf(dir+'Windy/WindyMASigned.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "varying-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"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\"\n",
    "API_ENDPOINT = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "def generate_chat_completion(messages, model=\"gpt-3.5-turbo\", temperature=1, max_tokens=None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "    }\n",
    "\n",
    "    if max_tokens is not None:\n",
    "        data[\"max_tokens\"] = max_tokens\n",
    "\n",
    "    response = requests.post(API_ENDPOINT, headers=headers, data=json.dumps(data))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        raise Exception(f\"Error {response.status_code}: {response.text}\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you create data based on real data'\"}\n",
    "]\n",
    "\n",
    "response_text = generate_chat_completion(messages)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incident-chicken",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 404\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"What are the benefits of using renewable energy?\"\n",
    "api_key = openai.api_key  # Replace with your actual API key\n",
    "\n",
    "response_text = chat_gpt4_api(prompt, api_key)\n",
    "if response_text:\n",
    "    print(f\"Response: {response_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "herbal-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "measured-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "potential-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the real-world data columns as a string and add it to the prompt\n",
    "x_values = df[\"xsrc\"].tolist()\n",
    "y_values = df[\"ysrc\"].tolist()\n",
    "odor_concentrations = df[\"odor\"].tolist()\n",
    "wind_u_velocities = df[\"U\"].tolist()\n",
    "wind_v_velocities = df[\"V\"].tolist()\n",
    "wind_directions = df[\"D\"].tolist()\n",
    "wind_speeds = df[\"S2\"].tolist()\n",
    "\n",
    "prompt = \"Generate more odor encounters based on the following data:\"\n",
    "\n",
    "# Split data into chunks of 10000 rows\n",
    "chunk_size = 1\n",
    "data_chunks = [df[i:i + chunk_size] for i in range(0, df.shape[0], chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "subjective-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate new data for each chunk of data\n",
    "# generated_data = \"\"\n",
    "# for chunk in data_chunks:\n",
    "#     odor = chunk[\"odor\"].tolist()\n",
    "\n",
    "\n",
    "\n",
    "#     data_str = \"\\n\".join([f\"{i+1}: Odor concentration {c}\" for i, ( c) \\\n",
    "#                           in enumerate(zip( odor))])\n",
    "#     chunk_prompt = f\"{prompt}\\n\\n{data_str}\"\n",
    "    \n",
    "#     # Call the GPT-3 API to generate new data based on the prompt\n",
    "#     response = openai.Completion.create(\n",
    "#         engine=\"text-davinci-002\",\n",
    "#         prompt=chunk_prompt,\n",
    "#         max_tokens=4096,\n",
    "#         temperature=0.5,\n",
    "#         n = 1,\n",
    "#         stop = None\n",
    "#     )\n",
    "    \n",
    "#     # Parse the response to extract the generated data\n",
    "#     generated_data += response.choices[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-argument",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
